# âš¡ directa-scraper

Fetch zero fees ETF and PAC entries from `directa.it`
Outputs JSONs and CSVs.

## ğŸš€ Quick Start

Follow these steps to get the `directa-scraper` up and running on your local machine.

### Prerequisites
-   **Python 3.x**: Ensure you have Python 3 installed. You can download it from [python.org](https://www.python.org/downloads/).

### Installation

1.  **Clone the repository**
    ```bash
    git clone https://github.com/mastershadow/directa-scraper.git
    cd directa-scraper
    ```

2.  **Install dependencies**
    ```bash
    pip install -r requirements.txt
    ```

### Usage

To run the scraper, execute the `main.py` script. The script's internal logic will determine the target URLs and data extraction rules.

```bash
python main.py
```

After execution, scraped data will typically be saved in the `out/` directory. You might need to inspect `main.py` to understand specific command-line arguments if supported, or to modify target URLs and extraction logic directly.

## ğŸ“ Project Structure

```
directa-scraper/
â”œâ”€â”€ .idea/                 # IDE configuration files
â”œâ”€â”€ data/                  # Placeholder for input/temporary data
â”œâ”€â”€ main.py                # Main scraping script
â”œâ”€â”€ out/                   # Directory for scraped output data
â””â”€â”€ requirements.txt       # Project dependencies
```

## âš™ï¸ Configuration

The primary configuration for `directa-scraper`, such as target URLs, specific selectors for data extraction, and output formats, is handled directly within the `main.py` script.

### Environment Variables
No explicit environment variables are currently used or required for this script.

### Configuration Files
-   `requirements.txt`: Manages Python package dependencies.
---

<div align="center">

**â­ Star this repo if you find it helpful!**

Made with â¤ï¸ by [mastershadow](https://github.com/mastershadow)

</div>